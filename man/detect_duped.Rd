% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/detect_duped.R
\name{detect_duped}
\alias{detect_duped}
\title{Test for duplicates}
\usage{
detect_duped(..., sep = "-^-")
}
\arguments{
\item{...}{vectors to concatenate.}

\item{sep}{a string used to when concatenating the vectors. See \code{\link[base]{interaction}}.}
}
\value{
A logical vector corresponding to values that are duplicates \emph{or are duplicated}.
}
\description{
Test for duplicates in one or a combination of vectors.
}
\details{
This function \strong{\emph{should not}} be used in places of \code{duplicated()} and \strong{\emph{does not return duplicates}}.
Instead, \code{detect_duped()} executes the common pattern

\code{vector \%in\% vector[duplicated(vector)]}.

Providing multiple vector arguments to \code{...} concatenates the vectors element-wise
before testing for duplicates in the new, collapsed vector.
}
\section{Profiling}{

I think the bottleneck here is the call to \code{interaction()}.
It might be worth benchmarking this against \code{paste()}.
It's possible that R does some internal operations when creating factors to optimize memory usage and speed up things like duplicated().
In that case, it's probably best to profile the entire function when testing,
rather than just compare the runtimes for different functions.
}

\examples{
state <- c("CA", "IL", "FL", "CA")
cd    <- c(22, 11, 22, 22)

data.frame(state, cd,
           dup = detect_duped(state, cd))

}
\seealso{
\code{\link[base]{duplicated}} and \code{\link[base]{interaction}}.
}
